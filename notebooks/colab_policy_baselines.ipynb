{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Kidney Allocation Policy Baselines \u2014 Colab\n", "This notebook runs urgency, utility, hybrid, and fairness-constrained policies on your synthetic data.\n", "You can **upload CSVs** or **mount Google Drive**. It also **writes `policy_baselines.py`** locally for a self-contained run."]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Install basics\n", "!pip -q install pandas numpy matplotlib scikit-learn"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Write the policy_baselines.py module into this runtime\n", "code = r\"\"\"\n", "import numpy as np\n", "import pandas as pd\n", "from collections import Counter\n", "\n", "ABO_RECIPIENTS = {\n", "    'O': ['O', 'A', 'B', 'AB'],\n", "    'A': ['A', 'AB'],\n", "    'B': ['B', 'AB'],\n", "    'AB': ['AB']\n", "}\n", "\n", "def compute_patient_features(df: pd.DataFrame):\n", "    out = df.copy()\n", "    out['EPTS_norm'] = out['EPTSScore'].clip(0,100) / 100.0\n", "    out['Age80'] = np.minimum(out['Age'], 80.0) / 80.0\n", "    urg_raw = np.log1p(out['DialysisYears'].clip(lower=0.0)) + 0.3 * out['Diabetes'].astype(float)\n", "    umin, umax = urg_raw.min(), urg_raw.max()\n", "    out['Urgency_norm'] = (urg_raw - umin) / (umax - umin + 1e-9)\n", "    no_tx = 5.0 - 0.6 * out['DialysisYears'] - 1.0 * out['Diabetes'].astype(float) - 0.5 * out['Age80']\n", "    out['NoTx'] = np.maximum(0.0, no_tx)\n", "    E = out['EPTS_norm'].values\n", "    Age80 = out['Age80'].values\n", "    out['A_part'] = 6.0 * (1.0 - E) + 1.0 * (1.0 - Age80) - out['NoTx'].values\n", "    out['B_part'] = 2.0 * (1.0 - E)\n", "    return out\n", "\n", "def bin_index(x, n_bins=10):\n", "    i = int(np.floor(x * n_bins))\n", "    if i >= n_bins: i = n_bins - 1\n", "    if i < 0: i = 0\n", "    return i\n", "\n", "def build_sorted_lists(pat_df: pd.DataFrame, policy: str, alpha: float = 0.5, n_bins: int = 10):\n", "    lists = {abo: {b: [] for b in range(n_bins)} for abo in ['O','A','B','AB']}\n", "    U = pat_df['Urgency_norm'].values.astype(float)\n", "    A = pat_df['A_part'].values.astype(float)\n", "    B = pat_df['B_part'].values.astype(float)\n", "    idx_by_abo = {abo: np.where(pat_df['BloodType'].values == abo)[0] for abo in ['O','A','B','AB']}\n", "    for b in range(n_bins):\n", "        x = (b + 0.5) / n_bins\n", "        util_key = A + B * x\n", "        kmin, kmax = util_key.min(), util_key.max()\n", "        util_norm = (util_key - kmin) / (kmax - kmin + 1e-9)\n", "        if policy == 'urgency':\n", "            key = U\n", "        elif policy == 'utility':\n", "            key = util_norm\n", "        elif policy == 'hybrid':\n", "            key = alpha * U + (1.0 - alpha) * util_norm\n", "        else:\n", "            raise ValueError(\"Unknown policy\")\n", "        for abo in ['O','A','B','AB']:\n", "            idxs = idx_by_abo[abo]\n", "            order = np.argsort(-key[idxs], kind='mergesort')\n", "            lists[abo][b] = idxs[order].tolist()\n", "    return lists\n", "\n", "def exact_utility_for_pair(pat_df_row, kdpi_norm):\n", "    E = float(pat_df_row['EPTS_norm']); K = float(kdpi_norm); Age80 = float(pat_df_row['Age80'])\n", "    theta0,theta1,theta2,theta3,theta4 = 5.0, 6.0, 3.0, 1.0, 2.0\n", "    post = theta0 + theta1*(1.0-E) + theta2*(1.0-K) + theta3*(1.0-Age80) + theta4*(1.0-E)*(1.0-K)\n", "    no_tx = float(pat_df_row['NoTx'])\n", "    util = max(post - no_tx, 0.0)\n", "    return util, post, no_tx\n", "\n", "def allocate(don_df: pd.DataFrame, pat_df: pd.DataFrame, policy: str, alpha: float = 0.5, fairness_eta: float = 0.0, n_bins: int = 10, group_col: str = 'Ethnicity'):\n", "    sorted_lists = build_sorted_lists(pat_df, policy, alpha, n_bins)\n", "    available = np.ones(len(pat_df), dtype=bool)\n", "    heads = {abo: {b: 0 for b in range(n_bins)} for abo in ['O','A','B','AB']}\n", "    # Groups\n", "    if group_col in pat_df.columns:\n", "        groups = pat_df[group_col].astype(str).values\n", "        gv, gc = np.unique(groups, return_counts=True)\n", "        p_share = {g: gc[i] / len(groups) for i,g in enumerate(gv)}\n", "    else:\n", "        groups = np.array(['All']*len(pat_df))\n", "        p_share = {'All': 1.0}\n", "    alloc_counts = Counter({g: 0 for g in p_share.keys()})\n", "    U = pat_df['Urgency_norm'].values.astype(float)\n", "    records = []\n", "    for d_idx,row in don_df.iterrows():\n", "        donor_bt = str(row['DonorBloodType'])\n", "        try:\n", "            kdpi = float(row['KDPI'])\n", "        except:\n", "            kdpi = float(pd.to_numeric(row['KDPI'], errors='coerce'))\n", "        K_norm = np.clip(kdpi, 0.0, 100.0) / 100.0\n", "        x = 1.0 - K_norm\n", "        b = bin_index(x, n_bins)\n", "        recipient_abos = ABO_RECIPIENTS.get(donor_bt, [])\n", "        restrict_group = None\n", "        if fairness_eta > 0 and len(records) > 0:\n", "            total_alloc = len(records)\n", "            deficits = {g: p_share[g]*total_alloc - alloc_counts[g] for g in p_share.keys()}\n", "            g_star, max_def = max(deficits.items(), key=lambda kv: kv[1])\n", "            if max_def > 0:\n", "                restrict_group = g_star\n", "        best_score, best_i, best_abo = -np.inf, None, None\n", "        for abo in recipient_abos:\n", "            lst = sorted_lists[abo][b]\n", "            h = heads[abo][b]\n", "            while h < len(lst) and (not available[lst[h]] or (restrict_group is not None and groups[lst[h]] != restrict_group)):\n", "                h += 1\n", "            heads[abo][b] = h\n", "            if h >= len(lst): continue\n", "            i = lst[h]\n", "            if policy == 'urgency':\n", "                score = U[i]\n", "            else:\n", "                util, post, no_tx = exact_utility_for_pair(pat_df.iloc[i], K_norm)\n", "                if policy == 'utility':\n", "                    score = util\n", "                elif policy == 'hybrid':\n", "                    util_norm = util / 12.0\n", "                    score = alpha * U[i] + (1.0 - alpha) * util_norm\n", "                else:\n", "                    score = util\n", "            if score > best_score:\n", "                best_score, best_i, best_abo = score, i, abo\n", "        if best_i is None: \n", "            continue\n", "        available[best_i] = False\n", "        heads[best_abo][b] += 1\n", "        util, post, no_tx = exact_utility_for_pair(pat_df.iloc[best_i], K_norm)\n", "        records.append({\n", "            'donor_index': d_idx, 'donor_bt': donor_bt, 'donor_kdpi': kdpi,\n", "            'recipient_index': int(best_i), 'recipient_bt': pat_df.iloc[best_i]['BloodType'],\n", "            'recipient_group': groups[best_i], 'urgency_norm': U[best_i],\n", "            'utility_years': util, 'post_years': post, 'no_tx_years': no_tx,\n", "            'policy': policy, 'alpha': alpha, 'fairness_eta': fairness_eta, 'group_col': group_col\n", "        })\n", "        alloc_counts[groups[best_i]] += 1\n", "    alloc_df = pd.DataFrame(records)\n", "    if len(alloc_df)==0:\n", "        return alloc_df, {}\n", "    total_benefit = alloc_df['utility_years'].sum()\n", "    mean_urg = alloc_df['urgency_norm'].mean()\n", "    alloc_share = alloc_df['recipient_group'].value_counts(normalize=True).to_dict()\n", "    for g in p_share.keys():\n", "        alloc_share.setdefault(g, 0.0)\n", "    disparity = 0.5 * sum(abs(alloc_share[g] - p_share[g]) for g in p_share.keys())\n", "    metrics = {'total_benefit_years': total_benefit, 'mean_urgency_norm': mean_urg, 'fairness_L1': disparity, 'n_assigned': len(alloc_df)}\n", "    return alloc_df, metrics\n", "\n", "def run_experiment(patients_csv: str, donors_csv: str, sample_patients: int = 20000, sample_donors: int = 3000, seed: int = 42, group_col: str = 'Ethnicity'):\n", "    patients = pd.read_csv(patients_csv).sample(n=sample_patients, random_state=seed).reset_index(drop=True)\n", "    donors = pd.read_csv(donors_csv).sample(n=sample_donors, random_state=seed).reset_index(drop=True)\n", "    patients_feat = compute_patient_features(patients)\n", "    results = []; allocations = {}\n", "    # Urgency\n", "    alloc, metr = allocate(donors, patients_feat, 'urgency', alpha=1.0, fairness_eta=0.0, group_col=group_col)\n", "    metr['policy']='Urgency'; metr['alpha']=1.0; metr['fairness_eta']=0.0\n", "    results.append(metr); allocations[('Urgency',1.0,0.0)] = alloc\n", "    # Utility\n", "    alloc, metr = allocate(donors, patients_feat, 'utility', alpha=0.0, fairness_eta=0.0, group_col=group_col)\n", "    metr['policy']='Utility'; metr['alpha']=0.0; metr['fairness_eta']=0.0\n", "    results.append(metr); allocations[('Utility',0.0,0.0)] = alloc\n", "    # Hybrid\n", "    for a in [0.25,0.5,0.75]:\n", "        alloc, metr = allocate(donors, patients_feat, 'hybrid', alpha=a, fairness_eta=0.0, group_col=group_col)\n", "        metr['policy']='Hybrid'; metr['alpha']=a; metr['fairness_eta']=0.0\n", "        results.append(metr); allocations[('Hybrid',a,0.0)] = alloc\n", "    # Fairness-constrained example\n", "    alloc, metr = allocate(donors, patients_feat, 'hybrid', alpha=0.5, fairness_eta=1.0, group_col=group_col)\n", "    metr['policy']='Hybrid+Fair'; metr['alpha']=0.5; metr['fairness_eta']=1.0\n", "    results.append(metr); allocations[('Hybrid+Fair',0.5,1.0)] = alloc\n", "    return pd.DataFrame(results), allocations\n", "\n", "def sweep(patients_csv: str, donors_csv: str, alphas, etas, sample_patients: int = 20000, sample_donors: int = 3000, seed: int = 42, group_col: str = 'Ethnicity'):\n", "    patients = pd.read_csv(patients_csv).sample(n=sample_patients, random_state=seed).reset_index(drop=True)\n", "    donors = pd.read_csv(donors_csv).sample(n=sample_donors, random_state=seed).reset_index(drop=True)\n", "    patients_feat = compute_patient_features(patients)\n", "    out = []; allocs = {}\n", "    # Always include urgency-only and utility-only\n", "    for policy, a, e in [('urgency',1.0,0.0), ('utility',0.0,0.0)]:\n", "        alloc, metr = allocate(donors, patients_feat, policy, alpha=a, fairness_eta=e, group_col=group_col)\n", "        metr['policy']=policy.title() if policy!='utility' else 'Utility'\n", "        metr['alpha']=a; metr['fairness_eta']=e\n", "        out.append(metr); allocs[(metr['policy'],a,e)] = alloc\n", "    # Hybrid grid\n", "    for a in alphas:\n", "        for e in etas:\n", "            alloc, metr = allocate(donors, patients_feat, 'hybrid', alpha=a, fairness_eta=e, group_col=group_col)\n", "            metr['policy']='Hybrid' if e==0 else 'Hybrid+Fair'\n", "            metr['alpha']=a; metr['fairness_eta']=e\n", "            out.append(metr); allocs[(metr['policy'],a,e)] = alloc\n", "    return pd.DataFrame(out), allocs\n", "\"\"\"\n", "with open('/content/policy_baselines.py','w') as f:\n", "    f.write(code)\n", "print('Wrote /content/policy_baselines.py')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load data\n", "Choose **one** of the two options below."]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Option A: Upload CSVs from your machine\n", "from google.colab import files\n", "import pandas as pd\n", "\n", "print(\"Upload patients.csv\")\n", "uploaded = files.upload()\n", "patients_path = [k for k in uploaded.keys() if k.endswith('.csv')][0]\n", "\n", "print(\"Upload donors.csv\")\n", "uploaded2 = files.upload()\n", "donors_path = [k for k in uploaded2.keys() if k.endswith('.csv')][0]\n", "\n", "print(\"patients:\", patients_path)\n", "print(\"donors:\", donors_path)"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Option B: Mount Drive (skip if you used uploads above)\n", "# from google.colab import drive\n", "# drive.mount('/content/drive')\n", "# patients_path = '/content/drive/MyDrive/path/to/patients.csv'\n", "# donors_path   = '/content/drive/MyDrive/path/to/donors.csv'"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Run demo experiment and a small sweep\n", "import pandas as pd\n", "from policy_baselines import run_experiment, sweep\n", "\n", "summary_df, _ = run_experiment(patients_path, donors_path, sample_patients=20000, sample_donors=3000, group_col='Ethnicity')\n", "summary_df"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Grid sweep over lambda (alphas) and fairness (etas)\n", "alphas = [0.25, 0.5, 0.75]\n", "etas = [0.0, 1.0]\n", "sweep_df, allocs = sweep(patients_path, donors_path, alphas, etas, sample_patients=20000, sample_donors=3000, group_col='Ethnicity')\n", "sweep_df"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Simple plots\n", "import matplotlib.pyplot as plt\n", "\n", "plt.figure()\n", "for _, row in sweep_df.iterrows():\n", "    label = f\"{row['policy']} (\u03b1={row['alpha']}, \u03b7={row['fairness_eta']})\"\n", "    plt.scatter(row['mean_urgency_norm'], row['total_benefit_years'])\n", "    plt.text(row['mean_urgency_norm'], row['total_benefit_years'], label, fontsize=8)\n", "plt.xlabel('Mean recipient urgency (normalized)')\n", "plt.ylabel('Total survival benefit (years)')\n", "plt.title('Urgency vs Total Benefit')\n", "plt.tight_layout()\n", "plt.savefig('/content/urgency_vs_benefit.png')\n", "print('Saved /content/urgency_vs_benefit.png')\n", "\n", "plt.figure()\n", "for _, row in sweep_df.iterrows():\n", "    label = f\"{row['policy']} (\u03b1={row['alpha']}, \u03b7={row['fairness_eta']})\"\n", "    plt.scatter(row['fairness_L1'], row['total_benefit_years'])\n", "    plt.text(row['fairness_L1'], row['total_benefit_years'], label, fontsize=8)\n", "plt.xlabel('Fairness disparity (L1)')\n", "plt.ylabel('Total survival benefit (years)')\n", "plt.title('Fairness vs Total Benefit')\n", "plt.tight_layout()\n", "plt.savefig('/content/fairness_vs_benefit.png')\n", "print('Saved /content/fairness_vs_benefit.png')"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null, "source": ["# Save outputs\n", "sweep_df.to_csv('/content/policy_comparison_summary.csv', index=False)\n", "print('Saved /content/policy_comparison_summary.csv')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}